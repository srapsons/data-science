{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "Guided project from dataquest.io\n",
    "\n",
    "This project will explore posts from Hacker News. Specifically Ask HN and Show HN posts, where users either ask the community a question or show the community something.\n",
    "We will assess which type of posts receive more comments, and assess where the time of posts affects the number of comments.\n",
    "\n",
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "# create list of lists from file\n",
    "from csv import reader\n",
    "opened_file = open('data/hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "# extract header row\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print(\"\\n\")\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data to Show and Ask posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask posts: 1744\n",
      "show posts: 1162\n",
      "other posts: 17194\n"
     ]
    }
   ],
   "source": [
    "# loop through the data to seperate posts into 3 lists, ask, show and other\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "# show number of each type of post        \n",
    "print('ask posts: ' + str(len(ask_posts)))\n",
    "print('show posts: ' + str(len(show_posts)))\n",
    "print('other posts: ' + str(len(other_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining average number of comments per post type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average comments for ask posts: 14.04\n"
     ]
    }
   ],
   "source": [
    "# get total comments for ask posts\n",
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = row[4]\n",
    "    total_ask_comments += int(num_comments)\n",
    "    \n",
    "# calculate the average\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(\"average comments for ask posts: {:.2f}\".format(avg_ask_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average comments for show posts: 10.32\n"
     ]
    }
   ],
   "source": [
    "# get total comments for show posts\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = row[4]\n",
    "    total_show_comments += int(num_comments)\n",
    "    \n",
    "# calculate the average\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(\"average comments for show posts: {:.2f}\".format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous cells we can see Ask HN posts receive on average four more comments than Show HN posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding number of ask posts and comments by time\n",
    "\n",
    "The analysis will focus on only the Ask posts, as they received more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 46, '13': 86, '10': 60, '14': 108, '16': 109, '23': 69, '12': 74, '17': 101, '15': 117, '21': 110, '20': 81, '02': 59, '18': 110, '03': 55, '05': 47, '19': 111, '01': 61, '22': 72, '08': 49, '04': 48, '00': 56, '06': 45, '07': 35, '11': 59}\n",
      "\n",
      "\n",
      "{'09': 257, '13': 1282, '10': 794, '14': 1419, '16': 1831, '23': 544, '12': 691, '17': 1147, '15': 4478, '21': 1749, '20': 1724, '02': 1384, '18': 1441, '03': 422, '05': 493, '19': 1191, '01': 716, '22': 481, '08': 497, '04': 340, '00': 457, '06': 398, '07': 269, '11': 643}\n"
     ]
    }
   ],
   "source": [
    "# import datetime module\n",
    "import datetime as dt\n",
    "\n",
    "# create new list of created dates and number of comments\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at,num_comments])\n",
    "    \n",
    "# create frequency tables as dictionaries for posts by hour and comments\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "# loop through new list\n",
    "for row in result_list:\n",
    "    str_date = row[0]\n",
    "    num_comments = row[1]\n",
    "    dt_date = dt.datetime.strptime(str_date,\"%m/%d/%Y %H:%M\") # parse date field as datetime\n",
    "    hour = dt_date.strftime(\"%H\") # extract only hour\n",
    "    if hour not in counts_by_hour:\n",
    "        # if new hour set count to 1 and comments\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = num_comments\n",
    "    if hour in counts_by_hour:\n",
    "        # if hour already in dictionary increment count by 1 and comments\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += num_comments\n",
    "        \n",
    "print(counts_by_hour)\n",
    "print(\"\\n\")\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average comments per post for each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.586956521739131], ['13', 14.906976744186046], ['10', 13.233333333333333], ['14', 13.13888888888889], ['16', 16.798165137614678], ['23', 7.884057971014493], ['12', 9.337837837837839], ['17', 11.356435643564357], ['15', 38.27350427350427], ['21', 15.9], ['20', 21.28395061728395], ['02', 23.45762711864407], ['18', 13.1], ['03', 7.672727272727273], ['05', 10.48936170212766], ['19', 10.72972972972973], ['01', 11.737704918032787], ['22', 6.680555555555555], ['08', 10.142857142857142], ['04', 7.083333333333333], ['00', 8.160714285714286], ['06', 8.844444444444445], ['07', 7.685714285714286], ['11', 10.898305084745763]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for row in comments_by_hour:\n",
    "    avg_by_hour.append([row,comments_by_hour[row]/counts_by_hour[row]])\n",
    "    \n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.586956521739131, '09'], [14.906976744186046, '13'], [13.233333333333333, '10'], [13.13888888888889, '14'], [16.798165137614678, '16'], [7.884057971014493, '23'], [9.337837837837839, '12'], [11.356435643564357, '17'], [38.27350427350427, '15'], [15.9, '21'], [21.28395061728395, '20'], [23.45762711864407, '02'], [13.1, '18'], [7.672727272727273, '03'], [10.48936170212766, '05'], [10.72972972972973, '19'], [11.737704918032787, '01'], [6.680555555555555, '22'], [10.142857142857142, '08'], [7.083333333333333, '04'], [8.160714285714286, '00'], [8.844444444444445, '06'], [7.685714285714286, '07'], [10.898305084745763, '11']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.27 average comments per post\n",
      "02:00: 23.46 average comments per post\n",
      "20:00: 21.28 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 15.90 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for row in sorted_swap[:5]:\n",
    "    hours = dt.datetime.strptime(row[1],\"%H\")\n",
    "    hours = hours.strftime(\"%H:%M\")\n",
    "    print(\"{}: {:.2f} average comments per post\".format(hours,row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Eastern US time posts created from 15:00 to 16:00 received the most comments.\n",
    "The ranges 15:00 to 17:00 and 20:00 to 22:00 are both the best windows to post for comments.\n",
    "\n",
    "The 20:00 to 22:00 Eastern US window is 02:00 in the UK, and not a reasonable time to be posting online.\n",
    "\n",
    "It would be best posting Ask HN posts from the UK from 20:00 to 22:00 to fall within the 15:00 to 16:00 Eastern US window. This will increase the likelihood of receiving comments from the Ask HN posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
